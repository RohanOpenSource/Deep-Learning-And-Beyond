{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohanOpenSource/Deep-Learning-And-Beyond/blob/main/HarryPotterLSTM%3C3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VDk8IpGTkRv"
      },
      "source": [
        "ON THIS FINE AND BEAUTIFUL DAY, we'll be making an lstm that generates text in the style of a harry potter script! I found this dataset yesterday and couldn't stop thinking about it haha.\n",
        "Here's the link: https://www.kaggle.com/datasets/gulsahdemiryurek/harry-potter-dataset?select=Harry+Potter+1.csv\n",
        "I will also try to use it to make a realistic sorting hat, but that may prove to be a bit complicated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aOcGkMQUAX7",
        "outputId": "3e038058-c3cd-4905-dae3-5213a1a8ba48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unique_chars: \t\n",
            " !\"&',-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz} –—’“”…﻿\n",
            "Number of characters: 202668\n",
            "Number of unique characters: 85\n"
          ]
        }
      ],
      "source": [
        "text = open(\"hp1.txt\").read()\n",
        "n_chars = len(text)\n",
        "vocab = ''.join(sorted(set(text)))\n",
        "print(\"unique_chars:\", vocab)\n",
        "n_unique_chars = len(vocab)\n",
        "print(\"Number of characters:\", n_chars)\n",
        "print(\"Number of unique characters:\", n_unique_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLibs3y5VZ5q"
      },
      "outputs": [],
      "source": [
        "char2int = {c: i for i, c in enumerate(vocab)}\n",
        "int2char = {i: c for i, c in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5sfh7BhVcud"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "BASENAME = os.path.basename(os.path.basename(\"hp1.txt\"))\n",
        "pickle.dump(char2int, open(f\"{BASENAME}-char2int.pickle\", \"wb\"))\n",
        "pickle.dump(int2char, open(f\"{BASENAME}-int2char.pickle\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXgBW8UqV_0K",
        "outputId": "a8e5e99f-cbee-4293-bbc7-110703a189a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "84 ﻿\n",
            "26 C\n",
            "57 h\n",
            "50 a\n",
            "67 r\n",
            "50 a\n",
            "52 c\n",
            "69 t\n",
            "54 e\n",
            "67 r\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "encoded_text = np.array([char2int[c] for c in text])\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
        "for char in char_dataset.take(10):\n",
        "    print(char.numpy(), int2char[char.numpy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqsU3Wm1WlMC",
        "outputId": "f13eee1d-6cf7-4b49-8bf6-0daeec8ff412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "﻿Character;Sentence\n",
            "Dumbledore;I should've known that you would be here, Professor McGonagall.\n",
            "McGonagall;Good evening, Professor Dumbledore.\n",
            "McGonagall;Are the rumors true, Albus?\n",
            "Dumbledore;I'm afraid so, professor.\n",
            "Dumbledore;The good and the bad.\n",
            "McGonagall;And the boy?\n",
            "Dumbledore;Hagrid is bringing him.\n",
            "McGonagall;Do you think it wise to trust Hagrid with something as important as this?\n",
            "Dumble\n",
            "dore;Ah, Professor, I would trust Hagrid with my life.\n",
            "Hagrid;Professor Dumbledore, sir.\n",
            "Hagrid;Professor McGonagall.\n",
            "Dumbledore;No problems, I trust, Hagrid?\n",
            "Hagrid;No, sir.\n",
            "Hagrid;Little tyke fell asleep just as we were flying over Bristol.\n",
            "Hagrid;Try not to wake him.\n",
            "Hagrid;There you go.\n",
            "Dumbledore;Albus, do you really think it's safe, leaving him with these people?\n",
            "McGonagall;I've watched them \n"
          ]
        }
      ],
      "source": [
        "sequences = char_dataset.batch(2*200 + 1, drop_remainder=True)\n",
        "for sequence in sequences.take(2):\n",
        "    print(''.join([int2char[i] for i in sequence.numpy()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4qrIyOtW9Pu"
      },
      "outputs": [],
      "source": [
        "def split_sample(sample):\n",
        "    ds = tf.data.Dataset.from_tensors((sample[:200], sample[200]))\n",
        "    for i in range(1, (len(sample)-1) // 2):\n",
        "        input_ = sample[i: i+200]\n",
        "        target = sample[i+200]\n",
        "        other_ds = tf.data.Dataset.from_tensors((input_, target))\n",
        "        ds = ds.concatenate(other_ds)\n",
        "    return ds\n",
        "\n",
        "dataset = sequences.flat_map(split_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcJos2FdZfvS"
      },
      "outputs": [],
      "source": [
        "def one_hot_samples(input_, target):\n",
        "    return tf.one_hot(input_, n_unique_chars), tf.one_hot(target, n_unique_chars)\n",
        "\n",
        "dataset = dataset.map(one_hot_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQEzNFgLZoyH",
        "outputId": "376ce974-dd71-473d-9c27-88002185ea43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: ﻿Character;Sentence\n",
            "Dumbledore;I should've known that you would be here, Professor McGonagall.\n",
            "McGonagall;Good evening, Professor Dumbledore.\n",
            "McGonagall;Are the rumors true, Albus?\n",
            "Dumbledore;I'm afra\n",
            "Target: i\n",
            "Input shape: (200, 85)\n",
            "Target shape: (85,)\n",
            "================================================== \n",
            "\n",
            "Input: Character;Sentence\n",
            "Dumbledore;I should've known that you would be here, Professor McGonagall.\n",
            "McGonagall;Good evening, Professor Dumbledore.\n",
            "McGonagall;Are the rumors true, Albus?\n",
            "Dumbledore;I'm afrai\n",
            "Target: d\n",
            "Input shape: (200, 85)\n",
            "Target shape: (85,)\n",
            "================================================== \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for element in dataset.take(2):\n",
        "    print(\"Input:\", ''.join([int2char[np.argmax(char_vector)] for char_vector in element[0].numpy()]))\n",
        "    print(\"Target:\", int2char[np.argmax(element[1].numpy())])\n",
        "    print(\"Input shape:\", element[0].shape)\n",
        "    print(\"Target shape:\", element[1].shape)\n",
        "    print(\"=\"*50, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9r1vM3fZzl5"
      },
      "outputs": [],
      "source": [
        "ds = dataset.repeat().shuffle(1024).batch(128, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-1AkeXCaAcN"
      },
      "source": [
        "Time for the actual LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BNpmLp8Z-gJ",
        "outputId": "127c8ccd-fd82-4332-b88d-cb9ca065be12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 200, 256)          350208    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 200, 256)          0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 256)               525312    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 85)                21845     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 897,365\n",
            "Trainable params: 897,365\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(256, input_shape=(200, n_unique_chars), return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.LSTM(256),\n",
        "    tf.keras.layers.Dense(n_unique_chars, activation=\"softmax\"),\n",
        "])\n",
        "model_weights_path = f\"results/{BASENAME}-{200}.h5\"\n",
        "model.summary()\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kB9Xt__Ha68X",
        "outputId": "f8ad430f-6ae4-4e3b-ee43-89e5b2dc1632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1581/1581 [==============================] - 121s 76ms/step - loss: 0.5129 - accuracy: 0.8293\n",
            "Epoch 2/30\n",
            "1581/1581 [==============================] - 122s 77ms/step - loss: 0.5044 - accuracy: 0.8318\n",
            "Epoch 3/30\n",
            "1581/1581 [==============================] - 118s 75ms/step - loss: 0.4924 - accuracy: 0.8366\n",
            "Epoch 4/30\n",
            "1581/1581 [==============================] - 118s 75ms/step - loss: 0.4821 - accuracy: 0.8393\n",
            "Epoch 5/30\n",
            "1581/1581 [==============================] - 119s 75ms/step - loss: 0.4717 - accuracy: 0.8423\n",
            "Epoch 6/30\n",
            "1581/1581 [==============================] - 119s 75ms/step - loss: 0.4646 - accuracy: 0.8455\n",
            "Epoch 7/30\n",
            "1581/1581 [==============================] - 119s 75ms/step - loss: 0.4546 - accuracy: 0.8480\n",
            "Epoch 8/30\n",
            "1581/1581 [==============================] - 118s 75ms/step - loss: 0.4487 - accuracy: 0.8497\n",
            "Epoch 9/30\n",
            "1581/1581 [==============================] - 118s 75ms/step - loss: 0.4405 - accuracy: 0.8520\n",
            "Epoch 10/30\n",
            "1581/1581 [==============================] - 119s 75ms/step - loss: 0.4314 - accuracy: 0.8550\n",
            "Epoch 11/30\n",
            "1581/1581 [==============================] - 118s 75ms/step - loss: 0.4267 - accuracy: 0.8566\n",
            "Epoch 12/30\n",
            "1581/1581 [==============================] - 119s 75ms/step - loss: 0.4190 - accuracy: 0.8584\n",
            "Epoch 13/30\n",
            "1581/1581 [==============================] - 118s 75ms/step - loss: 0.4109 - accuracy: 0.8612\n",
            "Epoch 14/30\n",
            "1581/1581 [==============================] - 118s 75ms/step - loss: 0.4081 - accuracy: 0.8617\n",
            "Epoch 15/30\n",
            "1581/1581 [==============================] - 118s 75ms/step - loss: 0.3999 - accuracy: 0.8644\n",
            "Epoch 16/30\n",
            "1581/1581 [==============================] - 118s 75ms/step - loss: 0.3937 - accuracy: 0.8669\n",
            "Epoch 17/30\n",
            "1581/1581 [==============================] - 119s 75ms/step - loss: 0.3897 - accuracy: 0.8681\n",
            "Epoch 18/30\n",
            "1581/1581 [==============================] - 118s 75ms/step - loss: 0.3845 - accuracy: 0.8698\n",
            "Epoch 19/30\n",
            "1581/1581 [==============================] - 119s 75ms/step - loss: 0.3830 - accuracy: 0.8698\n",
            "Epoch 20/30\n",
            "1581/1581 [==============================] - 119s 75ms/step - loss: 0.3796 - accuracy: 0.8709\n",
            "Epoch 21/30\n",
            "1581/1581 [==============================] - 118s 75ms/step - loss: 0.3778 - accuracy: 0.8718\n",
            "Epoch 22/30\n",
            "1581/1581 [==============================] - 119s 75ms/step - loss: 0.3688 - accuracy: 0.8748\n",
            "Epoch 23/30\n",
            "1581/1581 [==============================] - 119s 75ms/step - loss: 0.3937 - accuracy: 0.8661\n",
            "Epoch 24/30\n",
            "1581/1581 [==============================] - 118s 75ms/step - loss: 0.3514 - accuracy: 0.8803\n",
            "Epoch 25/30\n",
            "1581/1581 [==============================] - 118s 75ms/step - loss: 0.3568 - accuracy: 0.8781\n",
            "Epoch 26/30\n",
            "1581/1581 [==============================] - 119s 75ms/step - loss: 0.3519 - accuracy: 0.8810\n",
            "Epoch 27/30\n",
            "1581/1581 [==============================] - 118s 75ms/step - loss: 0.3520 - accuracy: 0.8797\n",
            "Epoch 28/30\n",
            "1581/1581 [==============================] - 119s 75ms/step - loss: 0.3446 - accuracy: 0.8826\n",
            "Epoch 29/30\n",
            "1581/1581 [==============================] - 118s 75ms/step - loss: 0.3457 - accuracy: 0.8828\n",
            "Epoch 30/30\n",
            "1581/1581 [==============================] - 118s 75ms/step - loss: 0.3409 - accuracy: 0.8847\n"
          ]
        }
      ],
      "source": [
        "if not os.path.isdir(\"results\"):\n",
        "    os.mkdir(\"results\")\n",
        "model.fit(ds, steps_per_epoch=(len(encoded_text) - 200) // 128, epochs=30)\n",
        "model.save(model_weights_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "seed = \"Hermione;How can you be nearly headless?\"\n",
        "s = seed\n",
        "n_chars = 400\n",
        "# generate 400 characters\n",
        "generated = \"\"\n",
        "for i in tqdm.tqdm(range(n_chars), \"Generating text\"):\n",
        "    # make the input sequence\n",
        "    X = np.zeros((1, 200, n_unique_chars))\n",
        "    for t, char in enumerate(seed):\n",
        "        X[0, (200 - len(seed)) + t, char2int[char]] = 1\n",
        "    # predict the next character\n",
        "    predicted = model.predict(X, verbose=0)[0]\n",
        "    # converting the vector to an integer\n",
        "    next_index = np.argmax(predicted)\n",
        "    # converting the integer to a character\n",
        "    next_char = int2char[next_index]\n",
        "    # add the character to results\n",
        "    generated += next_char\n",
        "    # shift seed and the predicted character\n",
        "    seed = seed[1:] + next_char\n",
        "\n",
        "print(\"Seed:\", s)\n",
        "print(\"Generated text:\")\n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmXA1lsjqg_k",
        "outputId": "1b77ed25-2b34-4640-ca68-9993779e39d7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating text: 100%|██████████| 400/400 [00:21<00:00, 18.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed: Hermione;How can you be nearly headless?\n",
            "Generated text:\n",
            "\n",
            "Hagrid;No, thanks, I'll stand at the request of the 3rrisher.\n",
            "Percy;Oh, We's come on now, him!\n",
            "Hagrid;I was my family for?\n",
            "Hermione;All right, well, he's got to hear before?\n",
            "Hagrid;Now, uh, you could be always fears the broom?\n",
            "Hermione;Alohomora\n",
            "Hermione;Get in\n",
            "Ron;Allast prenewt parents fought against him.\n",
            "Hagrid;But nobody lived once.\n",
            "Hagrid;Hello, professor.\n",
            "Percy;Oh, and keep and please that \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BEAUTIFUL! IT'S BETTER THAN CURSED CHILD! Ok maybe this isn't practical, but messing around with this is hilarious so mission accomplished."
      ],
      "metadata": {
        "id": "IVDMQp6m8v88"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HARRYPOTTERMYBELOVEDipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMFAuu1OfYQuK3d6b2flZtM",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}