{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EnsembleLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhGXOWF0mcVaXqvFbrVEQH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohanOpenSource/ml-notebooks/blob/main/EnsembleLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePONc_Zt46au"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xo02sc7xm5c0"
      },
      "source": [
        "Ensemble Learning, at it's core, is an enseble(many) models voting on the correct class name. The easiest way this can be implemented is taking the class which has been outputted by the majority of the models and outputting that. This is called hard voting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpGIzWmr0OCj"
      },
      "source": [
        "iris = load_iris()\n",
        "X = iris[\"data\"][:, (2, 3)] # this is the petal length and width\n",
        "y = iris[\"target\"]#boolean of whether the flower is an iris virginica or not as a float 64\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3H38nPo5Zoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6990f48c-8b8c-49ea-ff5e-3d5f41f4e6db"
      },
      "source": [
        "model_1 = RandomForestClassifier()\n",
        "model_2 = SVC()\n",
        "model_comb = VotingClassifier(\n",
        "    estimators=[('rfc', model_1), ('svc', model_2)],\n",
        "    voting='hard'\n",
        ")\n",
        "model_comb.fit(X_train, y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('rfc',\n",
              "                              RandomForestClassifier(bootstrap=True,\n",
              "                                                     ccp_alpha=0.0,\n",
              "                                                     class_weight=None,\n",
              "                                                     criterion='gini',\n",
              "                                                     max_depth=None,\n",
              "                                                     max_features='auto',\n",
              "                                                     max_leaf_nodes=None,\n",
              "                                                     max_samples=None,\n",
              "                                                     min_impurity_decrease=0.0,\n",
              "                                                     min_impurity_split=None,\n",
              "                                                     min_samples_leaf=1,\n",
              "                                                     min_samples_split=2,\n",
              "                                                     min_weight_fraction_leaf=0.0,\n",
              "                                                     n_estimators=100,\n",
              "                                                     n_jobs=None,\n",
              "                                                     oob_score=False,\n",
              "                                                     random_state=None,\n",
              "                                                     verbose=0,\n",
              "                                                     warm_start=False)),\n",
              "                             ('svc',\n",
              "                              SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                                  class_weight=None, coef0=0.0,\n",
              "                                  decision_function_shape='ovr', degree=3,\n",
              "                                  gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                                  probability=False, random_state=None,\n",
              "                                  shrinking=True, tol=0.001, verbose=False))],\n",
              "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
              "                 weights=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYHrzA3v1E6b",
        "outputId": "fa17dfaf-55b5-4786-b85f-eb4bc82caa1a"
      },
      "source": [
        "for clf in (model_1, model_2, model_comb):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier 1.0\n",
            "SVC 1.0\n",
            "VotingClassifier 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENCW1UEPnkK9"
      },
      "source": [
        "Hard voting hasn't given us great results. Let's try using bagging. Bagging is splitting the data into chunks and training each model on one of those chunks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGuEGzOBfyTf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efaddf4f-14ae-4439-b3fb-b70f7fe00f9f"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    SVC(), n_estimators=500,\n",
        "    max_samples=100, bootstrap=True, n_jobs=-1, oob_score=True\n",
        ") #setting the number of jobs to -1 tells sklearn to use all of the available cpu threads for this model.\n",
        "\n",
        "bag_clf.fit(X_train, y_train)\n",
        "bag_clf.oob_score_ #\"Out Of Bag\" score"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9464285714285714"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO1DTQG-9H3K"
      },
      "source": [
        "Time for Random Forests, one of the most powerful algorithms in ml is built of of the mediocre decision tree. A random forest is an ensemble of deicision trees trained on subsamples of the data. The label that is chosen by the majority of the trees is what is outputed by the forest. This eliminates the overfitting issue that is prevalent with decision trees. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3YjUXvU99EE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b85b4ac-4bcb-4dda-bfd9-3a77e923cb15"
      },
      "source": [
        "rfc_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
        "rfc_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rfc_clf.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-fXCwsnlGUl"
      },
      "source": [
        "Now lets make a random forest from it's counterpart to better understand what it is"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui4kVoSIk-Y-"
      },
      "source": [
        "decision_tree_clf = DecisionTreeClassifier(max_features=\"auto\", max_leaf_nodes=16)\n",
        "rfc_clf2 = BaggingClassifier(decision_tree_clf, n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1)#A random forest is simply an ensemble of decision trees with bagging\n",
        "rfc_clf2.fit(X_train, y_train)\n",
        "y_pred_2 = rfc_clf2.predict(X_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoLm1agNl6VO",
        "outputId": "5a2597a3-40ff-4600-e464-57e2c186062a"
      },
      "source": [
        "y_pred == y_pred_2"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8sr1k6YmdHk"
      },
      "source": [
        "These models are identcal, thus they have identical predictions. Now lets make a small random forest with Gradient Boosting. Gradient Boosting is when you train models in an ensemble on the residual errors of the previously trained model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgNnI999mi9M"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg1.fit(X_train, y_train);"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjE6s46zYVWa"
      },
      "source": [
        "y2 = y_train - tree_reg1.predict(X_train); #We train the second model on the residual errors of the first model\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg2.fit(X_train, y2);"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufy-tVUtYrEJ",
        "outputId": "1a631788-4935-49ef-cb57-99210a14e8f5"
      },
      "source": [
        "y3 = y2 - tree_reg2.predict(X_train) #The third model is trained on the residual errors of the seond model\n",
        "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg3.fit(X_train, y3)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=2,\n",
              "                      max_features=None, max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                      random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHgODLyeZAiq",
        "outputId": "09212ae9-66c7-4ad9-e57c-96f9430c37cc"
      },
      "source": [
        "y_pred = sum(tree.predict(X_test) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
        "y_pred, y_test"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 1.01449275, -0.01407867,  2.04107143,  1.01449275,  1.48214286,\n",
              "        -0.01407867,  1.01449275,  1.72857143,  1.01449275,  1.01449275,\n",
              "         1.72857143, -0.01407867, -0.01407867, -0.01407867, -0.01407867,\n",
              "         1.01449275,  2.04107143,  1.01449275,  1.01449275,  2.04107143,\n",
              "        -0.01407867,  1.72857143, -0.01407867,  2.04107143,  2.04107143,\n",
              "         2.04107143,  2.04107143,  2.04107143, -0.01407867, -0.01407867,\n",
              "        -0.01407867, -0.01407867,  1.01449275, -0.01407867, -0.01407867,\n",
              "         1.72857143,  1.01449275, -0.01407867]),\n",
              " array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "        0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUG2G7ond1MS"
      },
      "source": [
        "An easier way to do this is to use sklearn's built in Gradient Boosting Regressor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbxxgaWnbLJi",
        "outputId": "6ee2e5b2-368d-413b-cf6c-0680c3249527"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth = 2, n_estimators=3, learning_rate=1.0)\n",
        "gbrt.fit(X_train, y_train)\n",
        "y_pred = gbrt.predict(X_test)\n",
        "errors = [mean_squared_error(y_test, y_pred)]\n",
        "errors"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.014361159094852083]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXHQjwihib4Q"
      },
      "source": [
        "We have too few estimators. The optimal number of estimators can be found be taking the argmin of the errors of this model and then feeding 1+ that as the number of estimators in and otherwise identical model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUR53w2U22_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f6f1fc8-fae1-4a77-84b1-6f4a2c2348b0"
      },
      "source": [
        "gbrt2 = GradientBoostingRegressor(max_depth = 4, n_estimators=120)\n",
        "gbrt.fit(X_train, y_train)\n",
        "errors = [mean_squared_error(y_test, y_pred)\n",
        "        for y_pred in gbrt.staged_predict(X_test)]\n",
        "best_n = np.argmin(errors) + 1\n",
        "\n",
        "gbrt_best = GradientBoostingRegressor(max_depth=4, n_estimators=best_n)\n",
        "gbrt_best.fit(X_train, y_train)\n",
        "y_pred = gbrt_best.predict(X_test)\n",
        "errors = [mean_squared_error(y_test, y_pred)]\n",
        "errors"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.380367441622979]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY1zM8AJlsDW"
      },
      "source": [
        "Stacking is the final thing I will code in this notebook. The basis of stacking is rather than having a hard voting algorithm aggregate the predictions, we can train a model to do it for us. While this may make some angry citizens storm the capital building, it is for the greater good. Besides they would have stormed it anyways."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uls2pVpmBx-",
        "outputId": "6e04bf26-c7fd-4754-c01a-3acea543ad98"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import tensorflow as tf\n",
        "\n",
        "stacking_model_1 = GradientBoostingRegressor(max_depth=2, n_estimators=100)\n",
        "stacking_model_2 = RandomForestRegressor(max_depth=2, n_estimators=200)\n",
        "\n",
        "X_train_1, X_train_2, y_train_1, y_train_2 = train_test_split(X_train, y_train, test_size = 0.3)\n",
        "\n",
        "stacking_model_1.fit(X_train_1, y_train_1)\n",
        "stacking_model_2.fit(X_train_2, y_train_2)\n",
        "\n",
        "pred_1 = stacking_model_1.predict(X_train_2)\n",
        "pred_2 = stacking_model_2.predict(X_train_2)\n",
        "\n",
        "blender = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "blender.compile(loss=tf.keras.losses.mean_squared_error, optimizer = tf.keras.optimizers.Adam(), metrics=[\"mse\"])\n",
        "blender.fit(pred_1, y_train_2, epochs = 40)\n",
        "blender.fit(pred_2, y_train_2, epochs = 40)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 1.9703 - mse: 1.9703\n",
            "Epoch 2/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.6406 - mse: 1.6406\n",
            "Epoch 3/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.3996 - mse: 1.3996\n",
            "Epoch 4/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1441 - mse: 1.1441\n",
            "Epoch 5/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8521 - mse: 0.8521\n",
            "Epoch 6/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5509 - mse: 0.5509\n",
            "Epoch 7/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.2938 - mse: 0.2938\n",
            "Epoch 8/40\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1047 - mse: 0.1047\n",
            "Epoch 9/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 10/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1043 - mse: 0.1043\n",
            "Epoch 11/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1391 - mse: 0.1391\n",
            "Epoch 12/40\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1093 - mse: 0.1093\n",
            "Epoch 13/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0608 - mse: 0.0608\n",
            "Epoch 14/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0515 - mse: 0.0515\n",
            "Epoch 15/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0597 - mse: 0.0597\n",
            "Epoch 16/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0545 - mse: 0.0545\n",
            "Epoch 17/40\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0461 - mse: 0.0461\n",
            "Epoch 18/40\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0473 - mse: 0.0473\n",
            "Epoch 19/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 20/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0440 - mse: 0.0440\n",
            "Epoch 21/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 22/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0606 - mse: 0.0606\n",
            "Epoch 23/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 24/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0426 - mse: 0.0426\n",
            "Epoch 25/40\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0428 - mse: 0.0428\n",
            "Epoch 26/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0503 - mse: 0.0503\n",
            "Epoch 27/40\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0519 - mse: 0.0519\n",
            "Epoch 28/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0453 - mse: 0.0453\n",
            "Epoch 29/40\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0407 - mse: 0.0407\n",
            "Epoch 30/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0449 - mse: 0.0449\n",
            "Epoch 31/40\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0428 - mse: 0.0428\n",
            "Epoch 32/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0408 - mse: 0.0408\n",
            "Epoch 33/40\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 34/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 35/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0476 - mse: 0.0476\n",
            "Epoch 36/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0431 - mse: 0.0431\n",
            "Epoch 37/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0408 - mse: 0.0408\n",
            "Epoch 38/40\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0412 - mse: 0.0412\n",
            "Epoch 39/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0488 - mse: 0.0488\n",
            "Epoch 40/40\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 1/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 2/40\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0360 - mse: 0.0360\n",
            "Epoch 3/40\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0348 - mse: 0.0348\n",
            "Epoch 4/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0450 - mse: 0.0450\n",
            "Epoch 5/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0378 - mse: 0.0378\n",
            "Epoch 6/40\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0345 - mse: 0.0345\n",
            "Epoch 7/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0360 - mse: 0.0360\n",
            "Epoch 8/40\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0347 - mse: 0.0347\n",
            "Epoch 9/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0338 - mse: 0.0338\n",
            "Epoch 10/40\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0336 - mse: 0.0336\n",
            "Epoch 11/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0458 - mse: 0.0458\n",
            "Epoch 12/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0468 - mse: 0.0468\n",
            "Epoch 13/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0349 - mse: 0.0349\n",
            "Epoch 14/40\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0341 - mse: 0.0341\n",
            "Epoch 15/40\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0405 - mse: 0.0405\n",
            "Epoch 16/40\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0410 - mse: 0.0410\n",
            "Epoch 17/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0357 - mse: 0.0357\n",
            "Epoch 18/40\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0313 - mse: 0.0313\n",
            "Epoch 19/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0345 - mse: 0.0345\n",
            "Epoch 20/40\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0359 - mse: 0.0359\n",
            "Epoch 21/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0333 - mse: 0.0333\n",
            "Epoch 22/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0309 - mse: 0.0309\n",
            "Epoch 23/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0353 - mse: 0.0353\n",
            "Epoch 24/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0341 - mse: 0.0341\n",
            "Epoch 25/40\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0311 - mse: 0.0311\n",
            "Epoch 26/40\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0327 - mse: 0.0327\n",
            "Epoch 27/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0355 - mse: 0.0355\n",
            "Epoch 28/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0367 - mse: 0.0367\n",
            "Epoch 29/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0347 - mse: 0.0347\n",
            "Epoch 30/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0318 - mse: 0.0318\n",
            "Epoch 31/40\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0310 - mse: 0.0310\n",
            "Epoch 32/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0318 - mse: 0.0318\n",
            "Epoch 33/40\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0326 - mse: 0.0326\n",
            "Epoch 34/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0319 - mse: 0.0319\n",
            "Epoch 35/40\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0308 - mse: 0.0308\n",
            "Epoch 36/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0315 - mse: 0.0315\n",
            "Epoch 37/40\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0315 - mse: 0.0315\n",
            "Epoch 38/40\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0308 - mse: 0.0308\n",
            "Epoch 39/40\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0307 - mse: 0.0307\n",
            "Epoch 40/40\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0309 - mse: 0.0309\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcafb2d6590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHmk-yhHq769",
        "outputId": "108af8cb-c17f-475f-afe6-2f36bd917fde"
      },
      "source": [
        "p_1 = stacking_model_1.predict(X_test)\n",
        "p_2 = stacking_model_2.predict(X_test)\n",
        "\n",
        "blender.predict(p_1)\n",
        "blender.predict(p_2)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.0099456e+00],\n",
              "       [-9.4616320e-04],\n",
              "       [ 1.9535915e+00],\n",
              "       [ 1.0145307e+00],\n",
              "       [ 1.0711775e+00],\n",
              "       [-9.4616320e-04],\n",
              "       [ 1.0099456e+00],\n",
              "       [ 1.9019414e+00],\n",
              "       [ 1.0145307e+00],\n",
              "       [ 1.0099456e+00],\n",
              "       [ 1.9019414e+00],\n",
              "       [-9.4616320e-04],\n",
              "       [-9.4616320e-04],\n",
              "       [-9.4616320e-04],\n",
              "       [-9.4616320e-04],\n",
              "       [ 1.0269490e+00],\n",
              "       [ 1.9535915e+00],\n",
              "       [ 1.0099456e+00],\n",
              "       [ 1.0099456e+00],\n",
              "       [ 1.9535915e+00],\n",
              "       [-9.4616320e-04],\n",
              "       [ 1.5352073e+00],\n",
              "       [-9.4616320e-04],\n",
              "       [ 1.9535915e+00],\n",
              "       [ 1.9535915e+00],\n",
              "       [ 1.9019414e+00],\n",
              "       [ 1.9494067e+00],\n",
              "       [ 1.9535915e+00],\n",
              "       [-9.4616320e-04],\n",
              "       [-9.4616320e-04],\n",
              "       [-9.4616320e-04],\n",
              "       [-9.4616320e-04],\n",
              "       [ 1.0099456e+00],\n",
              "       [-9.4616320e-04],\n",
              "       [-9.4616320e-04],\n",
              "       [ 1.6401632e+00],\n",
              "       [ 1.0145307e+00],\n",
              "       [-9.4616320e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}